@article{TODO,
  author          = {TODO},
  journal         = {TODO},
  number          = {TODO},
  title           = {TODO},
  volume          = {TODO},
  year            = {TODO}
}


######################################################
# Pose estimation
######################################################
@article{openPose,
  author = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year = {2019}
}

@misc{HULC,
  doi = {10.48550/ARXIV.2205.05677},
  url = {https://arxiv.org/abs/2205.05677},
  author = {Shimada, Soshi and Golyanik, Vladislav and Li, Zhi and Pérez, Patrick and Xu, Weipeng and Theobalt, Christian},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense Contact Guidance},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

# Classic paper
@article{EndToEndPose,
  author    = {Angjoo Kanazawa and
               Michael J. Black and
               David W. Jacobs and
               Jitendra Malik},
  title     = {End-to-end Recovery of Human Shape and Pose},
  journal   = {CoRR},
  volume    = {abs/1712.06584},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.06584},
  eprinttype = {arXiv},
  eprint    = {1712.06584},
  timestamp = {Mon, 13 Aug 2018 16:49:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-06584.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



######################################################
# Human motion modelling
######################################################

##############
# Reviews
@misc{PoseEstimationBenchmarking,
  doi = {10.48550/ARXIV.2209.10529},
  url = {https://arxiv.org/abs/2209.10529},
  author = {Pang, Hui En and Cai, Zhongang and Yang, Lei and Zhang, Tianwei and Liu, Ziwei},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Benchmarking and Analyzing 3D Human Pose and Shape Estimation Beyond Algorithms},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}


##############
# Focus on Motion Priors
@inproceedings{humor,
    author={Rempe, Davis and Birdal, Tolga and Hertzmann, Aaron and Yang, Jimei and Sridhar, Srinath and Guibas, Leonidas J.},
    title={HuMoR: 3D Human Motion Model for Robust Pose Estimation},
    booktitle={International Conference on Computer Vision (ICCV)},
    year={2021}
}

@article{MotionVAE,
  author    = {Hung Yu Ling and
               Fabio Zinno and
               George Cheng and
               Michiel van de Panne},
  title     = {Character Controllers Using Motion VAEs},
  journal   = {CoRR},
  volume    = {abs/2103.14274},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.14274},
  eprinttype = {arXiv},
  eprint    = {2103.14274},
  timestamp = {Wed, 07 Apr 2021 15:31:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-14274.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DeepPhase,
author = {Starke, Sebastian and Mason, Ian and Komura, Taku},
title = {DeepPhase: Periodic Autoencoders for Learning Motion Phase Manifolds},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3528223.3530178},
doi = {10.1145/3528223.3530178},
abstract = {Learning the spatial-temporal structure of body movements is a fundamental problem for character motion synthesis. In this work, we propose a novel neural network architecture called the Periodic Autoencoder that can learn periodic features from large unstructured motion datasets in an unsupervised manner. The character movements are decomposed into multiple latent channels that capture the non-linear periodicity of different body segments while progressing forward in time. Our method extracts a multi-dimensional phase space from full-body motion data, which effectively clusters animations and produces a manifold in which computed feature distances provide a better similarity measure than in the original motion space to achieve better temporal and spatial alignment. We demonstrate that the learned periodic embedding can significantly help to improve neural motion synthesis in a number of tasks, including diverse locomotion skills, style-based movements, dance motion synthesis from music, synthesis of dribbling motions in football, and motion query for matching poses within large animation databases.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {136},
numpages = {13},
keywords = {character interactions, character animation, neural networks, character control, deep learning, human motion}
}

@article{MEVA,
  author    = {Zhengyi Luo and
               S. Alireza Golestaneh and
               Kris M. Kitani},
  title     = {3D Human Motion Estimation via Motion Compression and Refinement},
  journal   = {CoRR},
  volume    = {abs/2008.03789},
  year      = {2020},
  url       = {https://arxiv.org/abs/2008.03789},
  eprinttype = {arXiv},
  eprint    = {2008.03789},
  timestamp = {Wed, 02 Sep 2020 19:16:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2008-03789.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{TransformerVAEPrior,
  doi = {10.48550/ARXIV.2210.15134},
  url = {https://arxiv.org/abs/2210.15134},
  author = {Chen, Xin and Su, Zhuo and Yang, Lingbo and Cheng, Pei and Xu, Lan and Fu, Bin and Yu, Gang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences, I.4.8},
  title = {Learning Variational Motion Prior for Video-based Motion Capture},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@inproceedings{ConvAutoEnv2015,
  author = {Holden,
            Daniel and Saito,
            Jun and Komura,
            Taku and Joyce,
            Thomas},
  title = {Learning Motion Manifolds with Convolutional Autoencoders},
  year = {2015},
  isbn = {9781450339308},
  publisher = {Association for Computing Machinery},
  address = {New York,NY,USA},
  url = {https://doi.org/10.1145/2820903.2820918},
  doi = {10.1145/2820903.2820918},
  booktitle = {SIGGRAPH Asia 2015 Technical Briefs},
  articleno = {18},
  numpages = {4},
}

@article{ConvAutoEnv2016,
author = {Holden, Daniel and Saito, Jun and Komura, Taku},
title = {A Deep Learning Framework for Character Motion Synthesis and Editing},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/2897824.2925975},
doi = {10.1145/2897824.2925975},
abstract = {We present a framework to synthesize character movements based on high level parameters, such that the produced movements respect the manifold of human motion, trained on a large motion capture dataset. The learned motion manifold, which is represented by the hidden units of a convolutional autoencoder, represents motion data in sparse components which can be combined to produce a wide range of complex movements. To map from high level parameters to the motion manifold, we stack a deep feedforward neural network on top of the trained autoencoder. This network is trained to produce realistic motion sequences from parameters such as a curve over the terrain that the character should follow, or a target location for punching and kicking. The feedforward control network and the motion manifold are trained independently, allowing the user to easily switch between feedforward networks according to the desired interface, without re-training the motion manifold. Once motion is generated it can be edited by performing optimization in the space of the motion manifold. This allows for imposing kinematic constraints, or transforming the style of the motion, while ensuring the edited motion remains natural. As a result, the system can produce smooth, high quality motion sequences without any manual pre-processing of the training data.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {138},
numpages = {11},
keywords = {character animation, human motion, convolutional neural networks, manifold learning, autoencoder, deep learning}
}


##############
# Focus on inbetweening

# Very similar to MotionVAE
@article{learnedInbetweening,
	doi = {10.1145/3528223.3530090},
	url = {https://doi.org/10.1145%2F3528223.3530090},
	year = 2022,
	month = {jul},
	publisher = {Association for Computing Machinery ({ACM})},
	volume = {41},
	number = {4},
	pages = {1--10},
	author = {Xiangjun Tang and He Wang and Bo Hu and Xu Gong and Ruifan Yi and Qilong Kou and Xiaogang Jin},
	title = {Real-time controllable motion transition for characters},
	journal = {{ACM} Transactions on Graphics}
}

@article{structured4Dlatentspace,
  author    = {Mathieu Marsot and
               Stefanie Wuhrer and
               Jean{-}S{\'{e}}bastien Franco and
               Stephane Durocher},
  title     = {Multi-frame sequence generator of 4D human body motion},
  journal   = {CoRR},
  volume    = {abs/2106.04387},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.04387},
  eprinttype = {arXiv},
  eprint    = {2106.04387},
  timestamp = {Fri, 11 Jun 2021 11:04:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-04387.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

# Example RNN
@article{RobustMotionInbetweening,
  title={Robust motion in-betweening},
  author={F{\'e}lix G. Harvey and Mike Yurick and Derek Nowrouzezahrai and Christopher Joseph Pal},
  journal={ACM Transactions on Graphics (TOG)},
  year={2020},
  volume={39},
  pages={60:1 - 60:12}
}

##############
# Other approaches that identify motion as important aspect for pose estimation
@article{VIBE,
  author    = {Muhammed Kocabas and
               Nikos Athanasiou and
               Michael J. Black},
  title     = {{VIBE:} Video Inference for Human Body Pose and Shape Estimation},
  journal   = {CoRR},
  volume    = {abs/1912.05656},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.05656},
  eprinttype = {arXiv},
  eprint    = {1912.05656},
  timestamp = {Thu, 02 Jan 2020 18:08:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-05656.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{3DDynamicsFromVideo,
  author    = {Angjoo Kanazawa and
               Jason Y. Zhang and
               Panna Felsen and
               Jitendra Malik},
  title     = {Learning 3D Human Dynamics from Video},
  journal   = {CoRR},
  volume    = {abs/1812.01601},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.01601},
  eprinttype = {arXiv},
  eprint    = {1812.01601},
  timestamp = {Wed, 10 Jun 2020 08:58:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-01601.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Unified3DHumanMotionSynthesis,
  title={A Unified 3D Human Motion Synthesis Model via Conditional Variational Auto-Encoder∗},
  author={Yujun Cai and Yiwei Wang and Yiheng Zhu and Tat-Jen Cham and Jianfei Cai and Junsong Yuan and Jun Liu and Chuanxia Zheng and Sijie Yan and Henghui Ding and Xiaohui Shen and Ding Liu and Nadia Magnenat Thalmann},
  journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={11625-11635}
}

@article{ActionConditionedTransformer,
  title={Action-Conditioned 3D Human Motion Synthesis with Transformer VAE},
  author={Mathis Petrovich and Michael J. Black and G{\"u}l Varol},
  journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={10965-10975}
}

@article{MoGlow,
  author    = {Gustav Eje Henter and
               Simon Alexanderson and
               Jonas Beskow},
  title     = {MoGlow: Probabilistic and controllable motion synthesis using normalising
               flows},
  journal   = {CoRR},
  volume    = {abs/1905.06598},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.06598},
  eprinttype = {arXiv},
  eprint    = {1905.06598},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-06598.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


######################################################
# Pose completion
######################################################
@article{protores,
  author    = {Boris N. Oreshkin and
               Florent Bocquelet and
               F{\'{e}}lix G. Harvey and
               Bay Raitt and
               Dominic Laflamme},
  title     = {ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose},
  journal   = {CoRR},
  volume    = {abs/2106.01981},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.01981},
  eprinttype = {arXiv},
  eprint    = {2106.01981},
  timestamp = {Tue, 15 Jun 2021 11:31:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-01981.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}