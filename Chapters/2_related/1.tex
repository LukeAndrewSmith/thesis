To begin with, a review of Pose Estimation techniques is presented, as this forms an important part of the motion learning pipeline, which often operates on 2D/3D pose estimations. Next the motion prior literature is explored and related works for learning human motion are presented.


\section{Pose Estimation}
The existing pipeline for 2D pose estimation is based on Open Pose \cite{openPose}. OpenPose TODO


\section{Motion Priors}

Classical methods are presented in \cite{DeepPhase}, the involve matching/interpolating from existing databases.

The authors of HuMoR \cite{humor} presented a novel approach for learning and using a plausible motion prior. They train a conditional VAE that learns a distribution over latent transitions, in a canonical reference frame, between $\textit{states}$ that consist of a root translation, 3D joint positions, joint angles, and the respective velocities. They most notably use this model as a prior in a 'test time optimisation', which generates plausible sequence motions optimising for an initial state and a sequence of transitions starting from frame by frame estimates (2D/3D joints or points clouds). This optimisation includes, alongside others, a motion prior term based upon the conditional distribution $p(z_t|x_{t-1})$ that encourages plausible motion for the learned sequence. Note that the CVAE decoder also predicts ground plan contact alongside change in state, which are used as regularisers during their main use case 'test time optimisation'. The test time optimisation can operate on many modalities, 2D/3D joints, point clouds, etc., as the optimisation contains a Data Term $\epsilon_{data}$ that can be tailored to the modality as the HuMoR state is information rich, containing 3D joints (hence can fit to 2D joints through projection or directly to 3D) and can parametrise the SMPL model (hence the SMPL mesh can be correlated to point clouds). The initialisation for the test time optimisation is based upon VPoser TODO. 

HuMoR discussions:
\begin{itemize}
    \item Assumptions:
    \begin{itemize}
        \item The method necessitates knowledge of the ground plane, which is presently needed (empirical observation) for convergence during training (as the dataset is of motions with a flat ground), and thus also at test time even though it is not conceptually necessary
        \item Assumes static camera
    \end{itemize}
    \item Limitations:
    \begin{itemize}
        \item Single person formulation
    \end{itemize}
\end{itemize}

The authors of HuMoR \cite{humor} were inspired by the Motion VAE \cite{MVAE} paper. This paper uses an Conditional VAE (with assumed standard normal prior conditioning (vs. NN in HuMoR)) that directly outputs the next state (rather than the change in state in HuMoR). The model is used Autoregressively to predict motion (rather than the main presented use of HuMoR which is to fit motion to a sequence of existing 2D/3D joint predictions, though HuMoR can equally well be used autoregressively), and is trained with the typical ELBO in a supervised manner. \\
Some notes to self about MotionVAE
\begin{itemize}
    \item RL algo trained to walk the latent space
    \item Some notes about things they mention in the related work section:
    \begin{itemize}
        \item They cite [Wang et al. 2019] who train a stochastic generative model with output $\textit{processed by a refiner network to remove foot skating and add robustness}$.
    \end{itemize}
    \item Main differences to HuMoR
    \begin{itemize}
        \item c.f discussion section in HuMoR
        \item Conditional prior
        \item Predict change in motion
        \item Predict ground contacts
        \item Much additional regularisation in training
        \item Difference state representation (root projected to ground)
        \item Use of SMPL by HuMoR
        \item Difference in network architectures
        \begin{itemize}
            \item HuMoR just uses MLPs and MVAE decoder is a 'MANN-style mixture-of-expert neural network' (6 networks, gating network weighting their outputs)
            \item RELU in HuMoR, ELU in MVAE
            \item MVAE decoder has latent variable input at each layer (not sure about HuMoR)
        \end{itemize}
        \item 
    \end{itemize}
\end{itemize}


The learned-inbetweenings \cite{learnedInbetweening} paper is very similar to MVAE. They present a similar architecture except that they predict transitions as in HuMoR \cite{humor}, and that they seem to only predict the lower body joint velocities and rotations. The decoder architecture is similar with a gating network and multiple expert networks. They also train a sampler to sample from the latent space, similar to MVAE which trains a RL model.
Some notes to self about Learned-Inbetweenings
\begin{itemize}
    \item Contains a nice probabilistic formulation of the motion generation problem
\end{itemize}


There seem to be quite a number of works that present the CVAE architecture as a base with varying state representations, conditioning variables and loss terms, \cite{humor, learnedInbetweening, MVAE,structured4Dlatentspace}. \cite{humor} has a learned prior, , \cite{learnedInbetweening} has a normal prior and predicts


DeepPhase \cite{DeepPhase} proposes a convolutional autoencoder that operates on fixed length (TODO: I beleive fixed length) sequences of 3D joint velocities, learning a latent space that it encourages to represent sinusoidal functions (through phase/frequency/amplitude/offsets) that represent periodic features of motion. The auto-encoder maps to and from sequences of 3D joint velocities, and the latent variables represent a sequence of phase/etc. values over the whole motion, hence the change in parameters can represent a shift between different periodic motions and thus can describe non-periodic motions.


MEVA \cite{MEVA} postulates that learning a single motion model results in smooth motion, as on average human motion is smooth (i.e we are not shaking while walking (their words)), hence they propose a two stage pipeline, in which the results of VAE that esimates coarse motion is passed into a human shape regressor that refines the poses, the inputs are temporally correlated features hence temporal consistency is maintained. The paper also presents some motion specific data augmentation techniques, speed variation through sampling, mirroring, and root rotations. 
Some notes to self about Learned-Inbetweenings
\begin{itemize}
    \item TODO: very useful
    \item Nice related work section
    \item Nice dataset section
\end{itemize}


Another approach is presented in VIBE 



\subsection{Overview of Approaches}
We are most interested in models that learn plausible, task independent, human motion. These are refered to by \cite{MVAE} as $\textit{Motion-then-control}$ models. We limit our scope to parametric models.
\begin{itemize}
    \item MVAE \cite{humor}
    \begin{itemize}
        \item Standard normal CVAE
        \item Outputs next pose
        \item Decoder is mixture of networks
        \item Trained with rollout and scheduled sampling
        \item State positions referenced to root projection onto ground
        \item Nice investigation into using RL in the latent space for character control
        \item NOTE: Latent dimension size: 32 (typical physics based humanoid degrees of freedom).
        \item The state having velocities and the decoder predicting change in pose seems to implicitly model the time aspect of the motion, rather than explicitly modelling it like in \cite{structured4Dlatentspace}.
    \end{itemize}
    \item HuMoR \cite{humor}
    \begin{itemize}
        \item Parametrised conditional prior CVAE
        \item Outputs change in state and person ground contacts
        \item SMPL regularisers (a subset of their state parametrises the SMPL model)
        \item Motion learned in a canonical reference frame (TODO: not sure about MVAE)
        \item Trained without rollout (I beleive?) 
        \item State positions referenced as in SMPL model (to $(0,0)$?)
        \item Very nice feature of having velocities in the state and of predicting change in motion, this implicitly captures the direction of motion in time as well as in space 
    \end{itemize}
    \item Learned-inbetweenings paper \cite{learnedInbetweening}
    \begin{itemize}
        \item Bascially MVAE but outputs change in state like HuMoR
    \end{itemize}
    \item Structed latent space for 4D motion
    \begin{itemize}
        \item \cite{structured4Dlatentspace}
        \item VAE operating on a fixed number of frames but with 'varying duration' by including a timestamp per frame
        \item Conditions decoder with SMPL shape
        \item It encorporates a time element to distinguish the direction of motion (i.e to avoid having you sample backwards in time when you walk the latent space it's a direct next pose prediction and so clusters close poses in the latent space I beleive)
        \item They perform a comparison to other reconstruction methods to directly evaluate the VAE, not sure other papers did that much
        \item Didn't find the paper so interesting
    \end{itemize}
    \item DeepPhase
    \begin{itemize}
        \item Autoencoder operating on fixed length sequences of 3D joint velocities
        \item Latent space enforced to match sinusoidal functions that represent periodic motion
        \item Periodic functions can change over the length of the sequence thus shift between periodic motions and represent non-periodic motions
    \end{itemize}
    \item MEVA
    \begin{itemize}
        \item Separates pipeline into learning coarse motion VAE and refining this prediction
        \item VAE operates on features extracted with temporal convolutions directly from the image rather than on SMPL/joint position/velocity based state
        \item Augmentation techniques for AMASS, speed variation, mirroring and root rotations
        \item Nice related work and dataset sections
    \end{itemize}
    \item VIBE
    \begin{itemize}
        \item Estimates SMPL body parameters using a temporal generation network trained together with a motion discriminator
        \item GRU units
    \end{itemize}

    \item \textbf{Pose estimation}
    \item HULC
    \begin{itemize}
        \item Uses a scene point cloud to help generate dense contact estimation labels that are used to guide pose manifold sampling 
    \end{itemize}
    \item VPoser
    \begin{itemize}
        \item Not actually a motion prior, it's a pose prior
        \item Is used in Humor to help initialise the sequence of states
        \item VPoser is used by optimising pose directly in the latent space, the latent space is trained to be a normal distribution hence if you penalise the norm of the latent vector you are encouraging it to be close to what you've learned to be viable human poses (i.e close to the normal dist)
    \end{itemize}

    \item $\textbf{TODO: Things I haven't looked into so deeply}$
    \item RNNS
    \begin{itemize}
        \item \cite{RobustMotionInbetweening}
        \item Mixture-density network RNNs (MDN-RNNS)
        \begin{itemize}
            \item Referenced in \cite{MVAE}
            \item Output a distribution as a gaussian mixture model
        \end{itemize}
        \item SpatioTemporalRNN
        \begin{itemize}
            \item (https://arxiv.org/pdf/1908.07214.pdf) cited by  learned-inbetweening paper \cite{learnedInbetweening}
            \item Learns a manifold through encoder/decoder
            \item Separates 'spatial' and 'temporal' in encoder and decoder??
            \item Predicts in batches with RNN, they claim this forces the model to capture mid and long term connections (I beleive the explicit velocity modelling in HuMoR should do the same thing)
        \end{itemize}
    \end{itemize}
    \item Time-convolutional autoencoders
    \begin{itemize}
        \item Referenced in \cite{MVAE}
        \item Learns a latent motion manifold
    \end{itemize}
    \item Humor claims normalising flows and neural ODEs show potential but they only link to papers explaining these concepts and not actually using them for this purpose so not sure
    \begin{itemize}
        \item (Normalising flow: map to a simple distribution with an invertible function => tractable marginal likelihood (unlike with VAEs where we have to deal with an ELBO), but I'm not sure we care about the marginal likelihood in this case)
    \end{itemize}
\end{itemize}


The other possibile research direction related more to pose completion (or motion completion (though I assume motion completion would use similar methods to what was mentioned before)) in an animation setting.

\begin{itemize}
    \item Protores \cite{protores}
    \begin{itemize}
        \item Learned inverse kinematics solution
        \item Variable number of effector inputs processed and then mixed with a 'Proto' layer in the encoder
        \item Decoder takes the pose embedding and decodes the full pose (contains several blocks to separate the semantically different parts of the decoding process)
    \end{itemize}
\end{itemize}