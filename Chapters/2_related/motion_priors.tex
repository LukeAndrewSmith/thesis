\section{Motion Priors}

Classical methods are presented in \cite{DeepPhase}, the involve matching/interpolating from existing databases.

The authors of HuMoR \cite{humor} presented a novel approach for learning and using a plausible motion prior. They train a conditional VAE that learns a distribution over latent transitions, in a canonical reference frame, between $\textit{states}$ that consist of a root translation, 3D joint positions, joint angles, and the respective velocities. They most notably use this model as a prior in a 'test time optimisation', which generates plausible sequence motions optimising for an initial state and a sequence of transitions starting from frame by frame estimates (2D/3D joints or points clouds). This optimisation includes, alongside others, a motion prior term based upon the conditional distribution $p(z_t|x_{t-1})$ that encourages plausible motion for the learned sequence. Note that the CVAE decoder also predicts ground plan contact alongside change in state, which are used as regularisers during their main use case 'test time optimisation'. The test time optimisation can operate on many modalities, 2D/3D joints, point clouds, etc., as the optimisation contains a Data Term $\epsilon_{data}$ that can be tailored to the modality as the HuMoR state is information rich, containing 3D joints (hence can fit to 2D joints through projection or directly to 3D) and can parametrise the SMPL model (hence the SMPL mesh can be correlated to point clouds). The initialisation for the test time optimisation is based upon VPoser \TODO{Complete}. 

HuMoR discussions:
\begin{itemize}
    \item Assumptions:
    \begin{itemize}
        \item The method necessitates knowledge of the ground plane, which is presently needed (empirical observation) for convergence during training (as the dataset is of motions with a flat ground), and thus also at test time even though it is not conceptually necessary
        \item Assumes static camera
    \end{itemize}
    \item Limitations:
    \begin{itemize}
        \item Single person formulation
    \end{itemize}
\end{itemize}

The authors of HuMoR \cite{humor} were inspired by the Motion VAE \cite{MotionVAE} paper. This paper uses an Conditional VAE (with assumed standard normal prior conditioning (vs. NN in HuMoR)) that directly outputs the next state (rather than the change in state in HuMoR). The model is used Autoregressively to predict motion (rather than the main presented use of HuMoR which is to fit motion to a sequence of existing 2D/3D joint predictions, though HuMoR can equally well be used autoregressively), and is trained with the typical ELBO in a supervised manner. \\
Some notes to self about MotionVAE
\begin{itemize}
    \item RL algo trained to walk the latent space
    \item Some notes about things they mention in the related work section:
    \begin{itemize}
        \item They cite [Wang et al. 2019] who train a stochastic generative model with output $\textit{processed by a refiner network to remove foot skating and add robustness}$.
    \end{itemize}
    \item Main differences to HuMoR
    \begin{itemize}
        \item c.f discussion section in HuMoR
        \item Conditional prior
        \item Predict change in motion
        \item Predict ground contacts
        \item Much additional regularisation in training
        \item Difference state representation (root projected to ground)
        \item Use of SMPL by HuMoR
        \item Difference in network architectures
        \begin{itemize}
            \item HuMoR just uses MLPs and MotionVAE decoder is a 'MANN-style mixture-of-expert neural network' (6 networks, gating network weighting their outputs)
            \item RELU in HuMoR, ELU in MotionVAE
            \item MotionVAE decoder has latent variable input at each layer (not sure about HuMoR)
        \end{itemize}
        \item 
    \end{itemize}
\end{itemize}

The learned-inbetweenings \cite{learnedInbetweening} paper is very similar to MotionVAE. They present a similar architecture except that they predict transitions as in HuMoR \cite{humor}, and that they seem to only predict the lower body joint velocities and rotations. The decoder architecture is similar with a gating network and multiple expert networks. They also train a sampler to sample from the latent space, similar to MotionVAE which trains a RL model.
Some notes to self about Learned-Inbetweenings
\begin{itemize}
    \item Contains a nice probabilistic formulation of the motion generation problem
\end{itemize}


There seem to be quite a number of works that present the CVAE architecture as a base with varying state representations, conditioning variables and loss terms, \cite{humor, learnedInbetweening, MotionVAE,structured4Dlatentspace}. \cite{humor} has a learned prior, , \cite{learnedInbetweening} has a normal prior and predicts


DeepPhase \cite{DeepPhase} proposes a convolutional autoencoder that operates on fixed length \TODO{I beleive fixed length} sequences of 3D joint velocities, learning a latent space that it encourages to represent sinusoidal functions (through phase/frequency/amplitude/offsets) that represent periodic features of motion. The auto-encoder maps to and from sequences of 3D joint velocities, and the latent variables represent a sequence of phase/etc. values over the whole motion, hence the change in parameters can represent a shift between different periodic motions and thus can describe non-periodic motions.


MEVA \cite{MEVA} postulates that learning a single motion model results in smooth motion, as on average human motion is smooth (i.e we are not shaking while walking (their words)), hence they propose a two stage pipeline, in which the results of VAE that esimates coarse motion is passed into a human shape regressor that refines the poses, the inputs are temporally correlated features hence temporal consistency is maintained. The paper also presents some motion specific data augmentation techniques, speed variation through sampling, mirroring, and root rotations. 
Some notes to self about Learned-Inbetweenings
\begin{itemize}
    \item TODO: very useful
    \item Nice related work section
    \item Nice dataset section
\end{itemize}


Another approach is presented in VIBE 