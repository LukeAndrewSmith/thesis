\section{Future Work}
\label{sec:diffusion_future_work}

We have demonstrated that diffusion models represent an exciting research avenue and have laid a foundation of code for future research. The future directions that could build upon this work are numerous and potentially rich in their rewards. We will discuss some of the most promising avenues for future work in this section, and will also discuss some of the shortcomings of the work presented in this thesis.

\subsection{Model}
Some of the shortcomings of the model seen in Inpainting tasks, most notably in the Inbetweening task, are due to an inconsistency between the specified known motion and the motion subsequently generated during inpainting by the model. For the inbetweening task, if we avoid overwriting the generated motion with the known motion in the last denoising step, the motion is smooth over the whole sequence and the transition between known and generated motion contains no jump. The generated and known motion however do not match perfectly even at the last denoising step, that is to say, the part in the generated motion which will be overwritten by the known motion is not exactly the same as the known motion, and so when we override the generated motion with the known motion for the last time, we lose the smoothness of the motion and introduce a discontinuity between the generated and known motion. This effect was not just present in inbetweening, however also in the autocomplete and in replacing random missing joints over a whole sequence, and might be mitigated through several strategies. Firstly we might condition the model with an indication of where a known area is specified and penalize it during training for deviating from this known motion (as described in \secref{sec:autocomplete} but for sequence-level motion). Another method would simply be that of a postprocessing step, in which the known motion and the generated motion could be mixed for several frames at the transition point, thus achieving a smooth motion between the two. We must also note that this effect might be present in overfit models, as the model would be less free in the motion it is capable of generation, thus literature search into the presence of this effect in other models and more generally into modification to the inpainting procedure should be conducted.

There are many more exciting avenues for creating more task-specific models, for example, an inbetweening model could include a timestep embedding indicating the time till completion of the inbetweened motion, with the idea that the model can better blend the known and generated motion if has access to explicit information indicating at what point the motion should transition between the two. More generally, for any inpainting task, it could be interesting to condition explicitly on the known data and to penalize deviations from this known data during training.

The model training could also be improved. The stopping criteria are currently taken as the point where the loss visually seems to have converged on the loss graphs. This however is not a robust method as it does not not take into account the possibility of overfitting or the possibility of decreasing performance. This can be mitigated through the use of validation metrics as described in \secref{sec:future_work_evaluation}, or by a method such as that presented in \cite{MDM}, in which they retrospectively choose the checkpoint that minimizes the FID score.

Finally, more work could be directed toward the question of tuning the diffusion framework to motion modeling. Much of the literature \cite{EDGE,MDM,PhysDiff} bases itself primarily on the diffusion framework presented in \cite{ddpm} and satisfies itself in extending the DDPM implementation of diffusion. Therefore important, diffusion-specific hyperparameters such as the number of noising steps are not seemingly well explored in the context of motion modelling.

\subsection{Model use}

We noted through our studies that during the denoising procedure, the denoised $x_0$ often changed drastically throughout the process. At the beginning of the procedure when the network is predicting a denoised $x_0$ from Gaussian noise, it often resorts to predicting some mean motion. As this is incorporated into the latents the predicted $x_0$ motion shows more and more diversity, what we noted however is that this motion can change drastically, and can do so late in the denoising process. Intuition would suggest that as we become closer to the end of the denoising process, where there is less and less noise present in the latent variables we are denoising, the model should become more and more certain of its predicted motion and should not drastically change it. However, it sometimes did exactly that. This phenomenon is worth investigation, as it may indicate a flaw in the network, or perhaps represents an area for improvement.

We could also consider more test cases for the model to be evaluated on. Motion switching, which is a specific form of inbetweening where we attempt to join two distinct motion sequences (e.g from performing karate moves to sitting down) could also prove an interesting test. Many of the tests that were presented above did not require the model to inpaint a root translation, thus more tests where this is necessary will be an important avenue.

We could also consider test cases containing more structured noise, such as we encountered during the automated motion capture investigation in \chpref{chpt:humor} where legs are randomly swapped left to right and in which joints can be arbitrarily sticking out due to bad 2d pose estimates. We might approach this problem by modifying the inpainting procedure to deal with confidence estimates for the joints, performing the mixing between known and generated motion not through a binary mask, but a confidence-based mask.

\subsection{Model evaluation}
\label{sec:future_work_evaluation}

We presented an entirely qualitative evaluation of the models. As discussed previously, this was motivated by a shorter available time and a desire to get a better understanding of the models before investing time in a more rigorous evaluation. This however does not result in publishable or definite work, but rather a stepping stone toward such work indicating that it might be fruitful. Future work should therefore make more effort to investigate the models quantitatively. Relevant metrics should be explored for the tasks at hand (FID, KID, precision/recall, diversity \cite{Paper_with_useful_metrics_cited_by_MDM}). It would also be sensible to compare generated motion to the dataset, to see if the network has simply learned to memorise the dataset or if it is generating novel motion. Alternative baseline models should be discussed as well and comparisons should be made. For example, the missing state evaluation where a new subset of the joints is removed from each frame might well be accurately reconstructed by simple linear interpolation between the missing frames, so the model's performance might not be so impressive after all. It must also be noted that for the data with no forward/backward motion, the visualisations effectively hide/minimise foot sliding, as there is no global root translation a foot sliding while walking looks very similar to a foot that doesn't slide. As we saw with the data with a global root translation, the foot sliding is a serious issue and so this issue must be addressed.


\subsection{Data}
We note that our dataset, with approximately 45 minutes of motion spanning 4 subjects is significantly smaller than the AMASS \cite{amass} dataset used by many other papers that contains more than 40 hours of motion data spanning 300 subjects. We, therefore, expect that our model will generalise less well than if it were trained on the AMASS dataset. We also note however that this is not possible due to the licensing restrictions on the AMASS dataset limiting it to non-commercial use. If any of the models we explored in this thesis or subsequent work are to be productized, it would be prudent to obtain a larger dataset of motion, especially considering that the use cases in which such a system would be most helpful to an animator might well be those dealing with motion far from the data distribution we currently have, as the more obscure and intricate the motion sequence the harder it would be to animate and thus more value our system could provide.