\section{Motion Diffusion}
\label{sec:related_diffusion}

With the notable success of diffusion models in the image generation literature \cite{ddpm, diffusion_beats_gans, stable_diffusion}, diffusion models have begun to spread into many other fields within machine learning \cite{diffusion_review}, including the field of human motion modeling.

% \cite{diffusion_inpainting}

The authors of Avatars grow legs \cite{AvatarsGrowLegs} denoise a sequence of SMPL \cite{SMPL} parameters condition on sparse tracking inputs, notably taking the form of the orientation/translation of a headset and two hand controllers. They show that plausible motion can be generated from very sparse signals, thus indicating to us that the use of diffusion models in the rectification of occluded motion sequences is promising. Next, PhysDiff \cite{PhysDiff} provides a text-conditioned diffusion model with the unique use of a physics-based motion projection step in the diffusion process that helps to ensure the physical plausibility of the generated motion. The authors of EDGE \cite{EDGE} propose an attention-based, audio-conditioned diffusion framework for dance motion generation. With a similar architecture to that of EDGE \cite{EDGE} but using transformers as the base of the denoising network such that the attention mechanism can more easily be exploited across the whole motion sequence, the authors of MDM \cite{MDM} describe a text conditioned denoising architecture.

As we have seen, diffusion models can be employed in the field of motion modeling for a wide variety of tasks. Motion can be generated \cite{MDM, EDGE, AvatarsGrowLegs} conditioned on various inputs. Motion sequences can also be edited through inpainting \cite{diffusion_inpainting, MDM} to change only parts of a sequence, and motion inbetweening can also be achieved similarly \cite{MDM}. This wide variety of tasks that can be completed by a single model is a very attractive property of the diffusion framework and inspired us to investigate these models later in the thesis.