\section{Motion AutoEncoders}

A well-explored model is that of the AutoEncoder (AE) \cite{bank2021_autoencoders} or Variation-AutoEncoder (VAE) \cite{kingma2022_VAE}. These are popular models as they encourage the learning of a latent representation \cite{bank2021_autoencoders} of human motion, thus the intuition is that they learn not just to reproduce the data, but actually how humans move, providing a more robust prior.

% \TODO{MORE? c.f MEVA for nice related work section}

Holden et al. \cite{ConvAutoEnv2015} \cite{ConvAutoEnv2016} present simple CNN-based autoencoder architectures that operate on motion sequences. The notion of skeletal aware convolutions and pooling/unpooling operations for a VAE, alongside a sliding window method for motion rectification, are presented by the authors of \cite{HierarchicalMotionVAE}. \cite{TransformerVAEPrior} presents a novel approach of leaning a latent space, then projecting directly to this latent space from a motion sequence using a separate model, again operating directly on a motion sequence. The authors of MEVA \cite{MEVA} postulate that a VAE often learns only smooth motion, as we are asking too much of the model, thus present a pipeline in which a smooth motion and coarse motion VAEs are jointly used. Starke et. al present DeepPhase \cite{DeepPhase}, an autoencoder with a latent space enforced to match sinusoidal functions that represent periodic motion. Contrary to a common trope in sequence-level models, the authors of \cite{learnedInbetweening} and of \cite{MotionVAE} operate in a frame-to-frame regime, predicting the temporally local change of motion. Finally, a number of works present the Conditional-VAE architecture \cite{CVAE} as a base with varying state representations, conditioning variables and loss terms, \cite{humor, learnedInbetweening, MotionVAE, structured4Dlatentspace}.

As we can see, the literature is rich and diverse, but we found ourselves drawn to the HuMoR model \cite{humor}, due to its state-of-the-art performance and its use for the exact task that we desire to solve, that of rectifying a motion sequence captured through frame by frame pose estimation. The authors of \cite{humor} present a C-VAE architecture that learns a distribution over latent transitions, conditioned on the previous pose. They use this architecture alongside an optimisation method that rectifies human motion obtained from, among other modalities, RGB video through frame-by-frame pose estimation.

% HuMoR discussions:
% \begin{itemize}
%     \item Assumptions:
%     \begin{itemize}
%         \item The method necessitates knowledge of the ground plane, which is presently needed (empirical observation) for convergence during training (as the dataset is of motions with a flat ground), and thus also at test time even though it is not conceptually necessary
%         \item Assumes static camera
%     \end{itemize}
%     \item Limitations:
%     \begin{itemize}
%         \item Single person formulation
%     \end{itemize}
% \end{itemize}

% The authors of HuMoR \cite{humor} were inspired by the Motion VAE \cite{MotionVAE} paper. This paper uses an Conditional VAE (with assumed standard normal prior conditioning (vs. NN in HuMoR)) that directly outputs the next state (rather than the change in state in HuMoR). The model is used Autoregressively to predict motion (rather than the main presented use of HuMoR which is to fit motion to a sequence of existing 2D/3D joint predictions, though HuMoR can equally well be used autoregressively), and is trained with the typical ELBO in a supervised manner. \\
% Some notes to self about MotionVAE
% \begin{itemize}
%     \item RL algo trained to walk the latent space
%     \item Some notes about things they mention in the related work section:
%     \begin{itemize}
%         \item They cite [Wang et al. 2019] who train a stochastic generative model with output $\textit{processed by a refiner network to remove foot skating and add robustness}$.
%     \end{itemize}
%     \item Main differences to HuMoR
%     \begin{itemize}
%         \item c.f discussion section in HuMoR
%         \item Conditional prior
%         \item Predict change in motion
%         \item Predict ground contacts
%         \item Much additional regularisation in training
%         \item Difference state representation (root projected to ground)
%         \item Use of SMPL by HuMoR
%         \item Difference in network architectures
%         \begin{itemize}
%             \item HuMoR just uses MLPs and MotionVAE decoder is a 'MANN-style mixture-of-expert neural network' (6 networks, gating network weighting their outputs)
%             \item RELU in HuMoR, ELU in MotionVAE
%             \item MotionVAE decoder has latent variable input at each layer (not sure about HuMoR)
%         \end{itemize}
%         \item 
%     \end{itemize}
% \end{itemize}



% DeepPhase \cite{DeepPhase} proposes a convolutional autoencoder that operates on fixed length \TODO{I beleive fixed length} sequences of 3D joint velocities, learning a latent space that it encourages to represent sinusoidal functions (through phase/frequency/amplitude/offsets) that represent periodic features of motion. The auto-encoder maps to and from sequences of 3D joint velocities, and the latent variables represent a sequence of phase/etc. values over the whole motion, hence the change in parameters can represent a shift between different periodic motions and thus can describe non-periodic motions.

% MEVA \cite{MEVA} postulates that learning a single motion model results in smooth motion, as on average human motion is smooth (i.e we are not shaking while walking (their words)), hence they propose a two stage pipeline, in which the results of VAE that esimates coarse motion is passed into a human shape regressor that refines the poses, the inputs are temporally correlated features hence temporal consistency is maintained. The paper also presents some motion specific data augmentation techniques, speed variation through sampling, mirroring, and root rotations. 
% Some notes to self about Learned-Inbetweenings
% \begin{itemize}
%     \item TODO: very useful
%     \item Nice related work section
%     \item Nice dataset section
% \end{itemize}