\chapter*{Abstract}

Motion capture, the process of automatically recording the motion of a person or object, has firmly established itself as a key technology in modern animation pipelines since it provides real-time, high-quality, physically plausible results. However, the upfront costs for tailored software and hardware, cumbersome motion capture suits, and other issues represent a high barrier not only for individual artists but also for small teams. One way to overcome this barrier is with a system that can capture motion directly from RGB video. Such systems commonly perform pose estimation on the individual video frames and run the result through an optimizer to clean up the motion. While promising, such systems occasionally struggle with certain artifacts and with some occluded motions. The goal of this thesis is therefore to consider how we might train a general human motion model that could improve upon these shortcomings. To begin with, we take a state-of-the-art approach based on Variational Auto Encoders and investigate how to improve upon its issues to make it usable for our purposes. Next, we consider a relatively new class of models, diffusion models, which are proving to be powerful tools in many domains. We investigate the application of such models in the context of motion modeling and implement and evaluate a baseline model in order to conclude the feasibility of such models for our purposes.
 
\cleardoublepage
\chapter*{Zusammenfassung}

Motion Capture, die automatische Aufzeichnung der Bewegung einer Person oder eines Objekts, hat sich als Schlüsseltechnologie in modernen Animationspipelines etabliert, da sie qualitativ hochwertige, physikalisch plausible Ergebnisse in Echtzeit liefert. Allerdings stellen die Vorabkosten für maßgeschneiderte Software und Hardware, umständliche Motion-Capture-Anzüge und andere Probleme nicht nur für einzelne Künstler, sondern auch für kleine Teams eine hohe Hürde dar. Eine Möglichkeit, diese Hürde zu überwinden, ist ein System, das Bewegungen direkt aus RGB-Videos erfassen kann. Solche Systeme führen in der Regel eine Posenschätzung für die einzelnen Videobilder durch und lassen das Ergebnis durch einen Optimierer laufen, um die Bewegung zu bereinigen. Solche Systeme sind zwar vielversprechend, haben aber gelegentlich mit bestimmten Artefakten und verdeckten Bewegungen zu kämpfen. Ziel dieser Arbeit ist es daher, zu untersuchen, wie wir ein allgemeines menschliches Bewegungsmodell trainieren können, das diese Unzulänglichkeiten beheben kann. Zunächst nehmen wir einen modernen Ansatz, der auf Variational Auto Encoders basiert, und untersuchen, wie wir seine Probleme verbessern können, um ihn für unsere Zwecke nutzbar zu machen. Als Nächstes befassen wir uns mit einer relativ neuen Klasse von Modellen, den Diffusionsmodellen, die sich in vielen Bereichen als leistungsfähige Werkzeuge erweisen. Wir untersuchen die Anwendung solcher Modelle im Zusammenhang mit der Bewegungsmodellierung und implementieren und bewerten ein Basismodell, um die Durchführbarkeit solcher Modelle für unsere Zwecke zu prüfen.